{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dir = \"F:/TARGET frontier/TXT34/pickle_data/\"\n",
    "le_save = False\n",
    "model_save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"F:/TARGET frontier/TXT34/\"\n",
    "sample_data = pd.DataFrame([])\n",
    "for i in range(2015,2018+1):\n",
    "    data_name = \"train\"+str(i)\n",
    "    res = pd.read_csv(data_dir+data_name+\".csv\",encoding=\"shift-jis\")#,na_values=['--']\n",
    "    sample_data = pd.concat([sample_data,res])\n",
    "    \n",
    "#リークしないように慎重に！\n",
    "data_name = \"predict2019\"\n",
    "res = pd.read_csv(data_dir+data_name+\".csv\",encoding=\"shift-jis\")#,na_values=['--']\n",
    "predict_len = len(res)\n",
    "sample_data = pd.concat([sample_data,res])\n",
    "\n",
    "tail = \"fe3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214317, 46)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols = [\"コース区分\",\"多頭出し\"]\n",
    "train_data = sample_data.drop(drop_cols,axis=1)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_engineering():\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "        self.l = len(df)\n",
    "        \n",
    "    def labelencoding(self,col):\n",
    "        le = LabelEncoder()\n",
    "        le.fit(self.df[col])\n",
    "        if le_save:\n",
    "            with open(pickle_dir+tail+col+'.pickle', mode='wb') as fp:\n",
    "                pickle.dump(le, fp)\n",
    "        self.df[col] = le.transform(self.df[col])\n",
    "    \n",
    "    def more_than_double_le(self,lst):\n",
    "        a,b = lst[0],lst[1]\n",
    "        le = LabelEncoder()\n",
    "        le.fit(pd.concat([self.df[a],self.df[b]]))\n",
    "        if le_save:\n",
    "            with open(pickle_dir+tail+a+b+'.pickle', mode='wb') as fp:\n",
    "                pickle.dump(le, fp)\n",
    "        self.df[a] = le.transform(self.df[a])\n",
    "        self.df[b] = le.transform(self.df[b])\n",
    "        \n",
    "    def handle_nan(self,col):\n",
    "        self.df.fillna({col:\"--\"},inplace=True)\n",
    "        \n",
    "    def fill_nan(self,col):\n",
    "        self.df.fillna({col:\"0\"},inplace=True)\n",
    "    \n",
    "    def handle_mark(self,col):\n",
    "        self.df[col] = self.df[col].str.replace(\"△\",\"\")\n",
    "        self.df[col] = self.df[col].str.replace(\"▲\",\"\")\n",
    "        self.df[col] = self.df[col].str.replace(\"☆\",\"\")\n",
    "        #[\"△\",\"▲\",\"☆\"]\n",
    "    \n",
    "    def handle_class(self,col):\n",
    "        dic_class = {\"500万\":\"1勝\",\"1000万\":\"2勝\",\"1600万\":\"3勝\",\"OP(L)\":\"ｵｰﾌﾟﾝ\",\"重賞\":\"Ｇ３\",\"(不明)\":\"--\"}\n",
    "        self.df[col].replace(dic_class,inplace=True)\n",
    "        \n",
    "    def handle_specific_nan(self,col):\n",
    "        dic_specific = {\"----\":np.nan}\n",
    "        self.df[col].replace(dic_specific,inplace=True)\n",
    "    \n",
    "    def drop_row(self,col):\n",
    "        self.df.dropna(inplace=True,subset = [col])\n",
    "        self.df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    def handle_abs(self,col):\n",
    "        self.df[col] = self.df[col].astype(\"float64\")\n",
    "        self.df[col] = self.df[col].where(self.df[col]>0 , 0) #0より小さいなら0を入れてやる\n",
    "    \n",
    "    def set_validation(self,y_col,ozz_col):\n",
    "        self.df[ozz_col] = self.df[ozz_col].astype(\"float64\")\n",
    "        self.l = len(self.df)\n",
    "        res = np.array([0.0]*self.l)\n",
    "        \n",
    "        for i in range(self.l):\n",
    "            res[i] = (1/math.exp(3*self.df[y_col][i]))*(1/math.exp(1/self.df[ozz_col][i]*5)) #2/math.exp(1/i*3) min(50,self.df[ozz_col][i]) #1/math.exp(3*self.df[y_col][i])\n",
    "        self.df[y_col] = np.round(res,5)\n",
    "    \n",
    "    #わざと着差をいじる\n",
    "    def essence(self,y_col,ozz_col):\n",
    "        res = []\n",
    "        for i,j in zip(self.df[y_col],self.df[ozz_col]):\n",
    "            if i == 0 and 9 <= j <= 13:\n",
    "                res.append(i-0.3)\n",
    "            else:\n",
    "                res.append(i)\n",
    "        self.df[y_col] = pd.DataFrame(res)\n",
    "    \n",
    "    def ranking_and_number(self,ID_col):\n",
    "        ranking = []\n",
    "        number = []\n",
    "        num = 0\n",
    "        rank = 1\n",
    "        res = \"\"\n",
    "        for i,j in enumerate(self.df[ID_col]):\n",
    "            j = str(j)\n",
    "            if i == 0:\n",
    "                ranking.append(rank)\n",
    "                rank += 1\n",
    "                res = j[:-2]\n",
    "                num += 1\n",
    "                continue\n",
    "            if res != j[:-2]:\n",
    "                res = j[:-2]\n",
    "                number += [num]*num\n",
    "                rank = 1\n",
    "                ranking.append(rank)\n",
    "                rank += 1\n",
    "                num = 1\n",
    "            else:\n",
    "                num += 1\n",
    "                ranking.append(rank)\n",
    "                rank += 1\n",
    "        number += [num]*num\n",
    "        print(len(number))\n",
    "        print(len(ranking))\n",
    "        self.df = pd.concat([self.df,pd.Series(ranking,name=\"順位\"),pd.Series(number,name=\"頭数\")],axis=1)\n",
    "        \n",
    "    def basyo_kyori_sibadart(self,basyo,kyori,sibadart):\n",
    "        self.l = len(self.df)\n",
    "        res = []\n",
    "        for i in range(self.l):\n",
    "            if i%10000==0:\n",
    "                print(i)\n",
    "            b = self.df[basyo][i]\n",
    "            k = self.df[kyori][i]\n",
    "            s = self.df[sibadart][i]\n",
    "            if any(j == np.nan for j in [b,k,s]):\n",
    "                res.append(np.nan)\n",
    "            else:\n",
    "                res.append(str(b)+str(k)+str(s))\n",
    "        le = LabelEncoder()\n",
    "        le.fit(res)\n",
    "        res = le.transform(res)\n",
    "        name = basyo+\"距離芝ダ\"\n",
    "        res = pd.Series(res,name=name)\n",
    "        self.df =  pd.concat([self.df,res],axis=1)\n",
    "    \n",
    "    def convert_kyakusitu(self,col): #labelencodeより先にやること\n",
    "        self.l = len(self.df)\n",
    "        for i in range(self.l):\n",
    "            if self.df[col][i] == \"逃\":\n",
    "                self.df[col][i] = \"逃げ\"\n",
    "            elif self.df[col][i] == \"先\":\n",
    "                self.df[col][i] = \"先行\"\n",
    "            elif self.df[col][i] == \"中\":\n",
    "                self.df[col][i] = \"中団\"\n",
    "            elif self.df[col][i] == \"後\":\n",
    "                self.df[col][i] = \"後方\"\n",
    "            elif self.df[col][i] == \"マ\":\n",
    "                self.df[col][i] = \"ﾏｸﾘ\" #半角注意\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = Feature_engineering(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: 父タイプ名\n",
      "processing: 前走場所\n",
      "processing: 前芝・ダ\n",
      "processing: 前クラス名\n",
      "processing: 前走馬場状態\n",
      "processing: 前走脚質\n",
      "processing: 前好走\n",
      "processing: 替\n",
      "processing: 所属\n",
      "processing: 前騎手\n",
      "processing: 調教師\n"
     ]
    }
   ],
   "source": [
    "nan_cols = [\"父タイプ名\",\"前走場所\",\"前芝・ダ\",\"前クラス名\",\"前走馬場状態\",\"前走脚質\",\"前好走\",\"替\",\"所属\",\"前騎手\",\"調教師\"]\n",
    "for i in nan_cols:\n",
    "    print(\"processing:\",i)\n",
    "    fe.handle_nan(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: 複勝配当\n"
     ]
    }
   ],
   "source": [
    "fill_nan_with_0 = [\"複勝配当\"]\n",
    "for i in fill_nan_with_0:\n",
    "    print(\"processing:\",i)\n",
    "    fe.fill_nan(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: 斤量\n",
      "processing: 前走斤量\n"
     ]
    }
   ],
   "source": [
    "mark_cols = [\"斤量\",\"前走斤量\"]\n",
    "for i in mark_cols:\n",
    "    print(\"processing:\",i)\n",
    "    fe.handle_mark(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: クラス名\n",
      "processing: 前クラス名\n"
     ]
    }
   ],
   "source": [
    "h_class = [\"クラス名\",\"前クラス名\"]\n",
    "for i in h_class:\n",
    "    print(\"processing:\",i)\n",
    "    fe.handle_class(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: ['場所', '前走場所']\n",
      "processing: ['芝・ダ', '前芝・ダ']\n",
      "processing: ['馬場状態', '前走馬場状態']\n",
      "processing: ['クラス名', '前クラス名']\n",
      "processing: ['騎手', '前騎手']\n"
     ]
    }
   ],
   "source": [
    "double_le = [[\"場所\",\"前走場所\"],[\"芝・ダ\",\"前芝・ダ\"],[\"馬場状態\",\"前走馬場状態\"],[\"クラス名\",\"前クラス名\"],[\"騎手\",\"前騎手\"]]\n",
    "for i in double_le:\n",
    "    print(\"processing:\",i)\n",
    "    fe.more_than_double_le(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: 性別\n",
      "processing: 種牡馬\n",
      "processing: 父タイプ名\n",
      "processing: 前走脚質\n",
      "processing: 前好走\n",
      "processing: 替\n",
      "processing: 所属\n",
      "processing: 調教師\n"
     ]
    }
   ],
   "source": [
    "cat_cols = [\"性別\",\"種牡馬\",\"父タイプ名\",\"前走脚質\",\"前好走\",\"替\",\"所属\",\"調教師\"]\n",
    "for i in cat_cols:\n",
    "    print(\"processing:\",i)\n",
    "    fe.labelencoding(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 前走着差タイム\n",
      "processing 着差\n"
     ]
    }
   ],
   "source": [
    "specific_nan = [\"前走着差タイム\",\"着差\"]\n",
    "for i in specific_nan:\n",
    "    print(\"processing\",i)\n",
    "    fe.handle_specific_nan(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 単勝オッズ\n"
     ]
    }
   ],
   "source": [
    "drop_na = [\"単勝オッズ\"]\n",
    "for i in drop_na:\n",
    "    print(\"processing\",i)\n",
    "    fe.drop_row(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: 前走着差タイム\n",
      "processing: 着差\n"
     ]
    }
   ],
   "source": [
    "handle_abs = [\"前走着差タイム\",\"着差\"]\n",
    "for i in handle_abs:\n",
    "    print(\"processing:\",i)\n",
    "    fe.handle_abs(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'essence = [[\"着差\",\"単勝オッズ\"]]\\nfor i,j in essence:\\n    print(\"processing:\",i,j)\\n    fe.essence(i,j)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"essence = [[\"着差\",\"単勝オッズ\"]]\n",
    "for i,j in essence:\n",
    "    print(\"processing:\",i,j)\n",
    "    fe.essence(i,j)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214317\n",
      "214317\n"
     ]
    }
   ],
   "source": [
    "#順位、頭数は既に組み込み済み\n",
    "fe.ranking_and_number(\"レースID(旧)\")\n",
    "train_data = fe.df #これでranking_and_numberが反映される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: 場所 距離 芝・ダ\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "processing: 前走場所 前距離 前芝・ダ\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n"
     ]
    }
   ],
   "source": [
    "bks = [[\"場所\",\"距離\",\"芝・ダ\"],[\"前走場所\",\"前距離\",\"前芝・ダ\"]]\n",
    "for b,k,s in bks:\n",
    "    print(\"processing:\",b,k,s)\n",
    "    fe.basyo_kyori_sibadart(b,k,s)\n",
    "    train_data = fe.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#事故った時用にtrain_dataをdf型で保存しておく\n",
    "if model_save:\n",
    "    with open(pickle_dir+tail+\"train_data\"+'.pickle', mode='wb') as fp:\n",
    "        pickle.dump(train_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214317"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_len = len(train_data)\n",
    "all_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data.iloc[:all_len-predict_len-1]\n",
    "predict = train_data.iloc[all_len-predict_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(data_dir+\"train\"+tail+\".csv\",index=False,encoding=\"shift-jis\")\n",
    "predict.to_csv(data_dir+\"predict\"+tail+\".csv\",index=False,encoding=\"shift-jis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"with open(pickle_dir+tail+\"train_data\"+'.pickle', mode='rb') as fp:\n",
    "    train_data = pickle.load(fp)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ここからID検索、前5走取得、データフレーム変換  \n",
    "最初に、train_dataのindexをレースIDにする。  \n",
    "大本のデータフレーム名(実際にxgmachinaに使うもの)をbase_dfとする。  \n",
    "resを各レース情報とし、ここからres_dfにひとつずつ追加していく。  \n",
    "idファイルを読み込み、該当idのレースを引っ張ってきてres_dfに追加していく。  \n",
    "res_dfが完成したらbase_dfに追加し、res_dfを初期化する。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.set_index(\"レースID(旧)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2015\n",
    "id_df = pd.read_csv(data_dir+\"id\"+f\"{i}\"+\".csv\",encoding=\"shift-jis\",names=(\"日付データ\",\"今走\",\"前1走\",\"前2走\",\"前3走\",\"前4走\",\"前5走\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.iloc[0][[\"騎手\",\"前騎手\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = [\"レースID(旧)\",\"場所\",\"芝・ダ\",\"距離\",\"クラス名\",\"馬場状態\",\"頭数\",\"騎手\",\"枠番\",\"性別\",\"年齢\",\"キャリア\",\"斤量\",\"間隔\",\"休み明け〜戦目\",\"種牡馬\",\"父タイプ名\",\"所属\",\"調教師\",\"確定着順\",\"着差\",\"単勝オッズ\",\"複勝オッズ下限\",\n",
    "                \"複勝オッズ上限\",\"複勝配当\",\"前走レースID(旧)\",\"前走場所\",\"前芝・ダ\",\"前距離\",\"前クラス名\",\"前走馬場状態\",\"前走出走頭数\",\"替\",\"前騎手\",\"前走枠番\",\"前走脚質\",\"前走斤量\",\"前走Ave-3F\",\"前走上り3F\",\"前走PCI3\",\n",
    "                \"前走RPCI\",\"前PCI\",\"前好走\",\"前走確定着順\",\"前走着差タイム\",\"前走単勝オッズ\",\"場所距離芝ダ\",\"前走場所距離芝ダ\",\"前走レースID(旧)1\",\"前走場所1\",\"前芝・ダ1\",\"前距離1\",\"前クラス名1\",\"前走馬場状態1\",\"前走出走頭数1\",\n",
    "                \"替1\",\"前騎手1\",\"前走枠番1\",\"前走脚質1\",\"前走斤量1\",\"前走Ave-3F1\",\"前走上り3F1\",\"前走PCI31\",\"前走RPCI1\",\"前PCI1\",\"前好走1\",\"前走確定着順1\",\"前走着差タイム1\",\"前走単勝オッズ1\",\"場所距離芝ダ1\",\"前走場所距離芝ダ1\",\n",
    "                \"前走レースID(旧)2\",\"前走場所2\",\"前芝・ダ2\",\"前距離2\",\"前クラス名2\",\"前走馬場状態2\",\"前走出走頭数2\",\"替2\",\"前騎手2\",\"前走枠番2\",\"前走脚質2\",\"前走斤量2\",\"前走Ave-3F2\",\"前走上り3F2\",\"前走PCI32\",\"前走RPCI2\",\n",
    "                \"前PCI2\",\"前好走2\",\"前走確定着順2\",\"前走着差タイム2\",\"前走単勝オッズ2\",\"場所距離芝ダ2\",\"前走場所距離芝ダ2\",\"前走レースID(旧)3\",\"前走場所3\",\"前芝・ダ3\",\"前距離3\",\"前クラス名3\",\"前走馬場状態3\",\"前走出走頭数3\",\n",
    "                \"替3\",\"前騎手3\",\"前走枠番3\",\"前走脚質3\",\"前走斤量3\",\"前走Ave-3F3\",\"前走上り3F3\",\"前走PCI33\",\"前走RPCI3\",\"前PCI3\",\"前好走3\",\"前走確定着順3\",\"前走着差タイム3\",\"前走単勝オッズ3\",\"場所距離芝ダ3\",\"前走場所距離芝ダ3\",\n",
    "                \"前走レースID(旧)4\",\"前走場所4\",\"前芝・ダ4\",\"前距離4\",\"前クラス名4\",\"前走馬場状態4\",\"前走出走頭数4\",\"替4\",\"前騎手4\",\"前走枠番4\",\"前走脚質4\",\"前走斤量4\",\"前走Ave-3F4\",\"前走上り3F4\",\"前走PCI34\",\"前走RPCI4\",\n",
    "                \"前PCI4\",\"前好走4\",\"前走確定着順4\",\"前走着差タイム4\",\"前走単勝オッズ4\",\"場所距離芝ダ4\",\"前走場所距離芝ダ4\",\"前走レースID(旧)5\",\"前走場所5\",\"前芝・ダ5\",\"前距離5\",\"前クラス名5\",\"前走馬場状態5\",\"前走出走頭数5\",\"替5\",\n",
    "                \"前騎手5\",\"前走枠番5\",\"前走脚質5\",\"前走斤量5\",\"前走Ave-3F5\",\"前走上り3F5\",\"前走PCI35\",\"前走RPCI5\",\"前PCI5\",\"前好走5\",\"前走確定着順5\",\"前走着差タイム5\",\"前走単勝オッズ5\",\"場所距離芝ダ5\",\"前走場所距離芝ダ5\",\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.to_dict(orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = id_df.iloc[33000][1]\n",
    "print(int(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(train_data.keys()):\n",
    "    if 32999 <= i <= 33001:\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t1 = 0\n",
    "t2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.DataFrame(columns=columns_name)\n",
    "e1 = []\n",
    "e2 = []\n",
    "for i in range(2015,2019+1):\n",
    "    id_df = pd.read_csv(data_dir+\"id\"+f\"{i}\"+\".csv\",encoding=\"shift-jis\",names=(\"日付データ\",\"今走\",\"前1走\",\"前2走\",\"前3走\",\"前4走\",\"前5走\"))\n",
    "    id_df = id_df.values.tolist()\n",
    "    res_df = pd.DataFrame(columns=columns_name)\n",
    "    res_res_df = pd.DataFrame(columns=columns_name)\n",
    "    for j in range(len(id_df)):\n",
    "        if j%1000==0:\n",
    "            t2 = time.time()\n",
    "            print(\"processing:\",i,j,t2-t1)\n",
    "            t1 = t2\n",
    "        for k in range(6):\n",
    "            if k == 0: #今走の場合のみ、今走のデータを取り出す\n",
    "                try:\n",
    "                    race_id = id_df[j][k+1]\n",
    "                    res = pd.Series({\"レースID(旧)\":race_id})\n",
    "                    res = res.append(pd.Series(train_data[race_id]))\n",
    "                    continue\n",
    "                except: #ここでエラー出たらもうしょうがないので飛ばす\n",
    "                    try:\n",
    "                        race_id = int(id_df[j][k+1])\n",
    "                        res = pd.Series({\"レースID(旧)\":race_id})\n",
    "                        res = res.append(pd.Series(train_data[race_id]))\n",
    "                        continue\n",
    "                    except:\n",
    "                        e1.append(race_id)\n",
    "                        break\n",
    "            race_id = id_df[j][k+1]\n",
    "            #race_id = id_df.iloc[j][f\"前{k}走\"]\n",
    "            if race_id != np.nan:\n",
    "                try:\n",
    "                    race_data = pd.Series(train_data[race_id])\n",
    "                    race_data = race_data[[\"前走レースID(旧)\",\"前走場所\",\"前芝・ダ\",\"前距離\",\"前クラス名\",\"前走馬場状態\",\"前走出走頭数\",\"替\",\n",
    "                                                         \"前騎手\",\"前走枠番\",\"前走脚質\",\"前走斤量\",\"前走Ave-3F\",\"前走上り3F\",\"前走PCI3\",\"前走RPCI\",\"前PCI\",\n",
    "                                                         \"前好走\",\"前走確定着順\",\"前走着差タイム\",\"前走単勝オッズ\",\"場所距離芝ダ\",\"前走場所距離芝ダ\"]]\n",
    "                    race_data = race_data.rename(index=lambda s: s+str(k))\n",
    "                    res = res.append(race_data) #必要なデータだけで良い\n",
    "                except:\n",
    "                    break\n",
    "            else: #レースIDが欠損してた場合\n",
    "                break\n",
    "        \n",
    "        res.name = j#res:馬毎\n",
    "        res_df = res_df.append(res) #res_df:年毎\n",
    "        if j%500==0:\n",
    "            res_res_df = pd.concat([res_res_df,res_df])\n",
    "            res_df = pd.DataFrame(columns=columns_name)\n",
    "    #最後の処理(i%500でひっかからない最後)\n",
    "    res_res_df = pd.concat([res_res_df,res_df])\n",
    "    res_df = pd.DataFrame(columns=columns_name)\n",
    "    \n",
    "    base_df = pd.concat([base_df,res_res_df])\n",
    "    res_res_df = pd.DataFrame(columns=columns_name)\n",
    "    #base_df = base_df.append(res_res_df) #base_df:全データ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_dir+tail+\"base_df\"+'.pickle', mode='wb') as fp:\n",
    "        pickle.dump(base_df, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"with open(pickle_dir+tail+\"base_df\"+'.pickle', mode='rb') as fp:\n",
    "    base_df = pickle.load(fp)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_len : 2013-2019年までの全データ長  \n",
    "train_all_len : 2015-2019までのデータ長  \n",
    "train_len : 2015-2018まで  \n",
    "predict_len : 2019年のデータ長  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_len = len(train_data)\n",
    "all_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_len = len(base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = base_df.iloc[:train_all_len-predict_len-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = base_df.iloc[train_all_len-predict_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predict) #predoct_lenと一致しているか確認！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_save:\n",
    "    with open(pickle_dir+tail+\"train\"+'.pickle', mode='wb') as fp:\n",
    "        pickle.dump(train, fp)\n",
    "if model_save:\n",
    "    with open(pickle_dir+tail+\"predict\"+'.pickle', mode='wb') as fp:\n",
    "        pickle.dump(predict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(data_dir+\"train\"+tail+\".csv\",index=False,encoding=\"shift-jis\")\n",
    "predict.to_csv(data_dir+\"predict\"+tail+\".csv\",index=False,encoding=\"shift-jis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
